{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a769d70",
   "metadata": {},
   "source": [
    "# 🧠 Neuron trong snnTorch\n",
    "\n",
    "`snnTorch` được thiết kế để hoạt động trực quan với PyTorch, cho phép mỗi nơ-ron spiking có thể được sử dụng giống như một hàm kích hoạt (activation function) trong chuỗi các lớp mạng.\n",
    "\n",
    "## 🔧 Đặc điểm chính\n",
    "\n",
    "- Nhiều loại nơ-ron spiking có sẵn, hoạt động giống như các lớp activation trong PyTorch.\n",
    "- Mỗi lớp nơ-ron spiking **không phụ thuộc vào** các lớp liền kề như:\n",
    "  - Fully-connected\n",
    "  - Convolutional\n",
    "  - Residual connections, v.v.\n",
    "\n",
    "- Mô hình nơ-ron được biểu diễn bằng hàm đệ quy → **không cần lưu vết điện thế màng** → tiết kiệm bộ nhớ.\n",
    "- Có thể huấn luyện cả mạng nhỏ và lớn trên **CPU hoặc GPU**.\n",
    "- Tích hợp sâu với `torch.autograd`, hỗ trợ tăng tốc bằng GPU tương tự như PyTorch.\n",
    "\n",
    "## 🚫 Gradient và cơ chế thay thế\n",
    "\n",
    "- Mặc định, PyTorch sẽ không truyền gradient qua các hàm ngưỡng (threshold) do chúng không khả vi.\n",
    "- `snnTorch` dùng `snntorch.neurons.Heaviside` để **ghi đè gradient mặc định**.\n",
    "- Có thể sử dụng các hàm gradient thay thế khác từ `snntorch.surrogate`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 Các loại nơ-ron hỗ trợ\n",
    "\n",
    "| Tên Neuron | Mô tả |\n",
    "|------------|-------|\n",
    "| `Leaky` | Nơ-ron LIF bậc 1 (Leaky Integrate-and-Fire) |\n",
    "| `RLeaky` | Giống trên, có thêm kết nối hồi tiếp |\n",
    "| `Synaptic` | LIF bậc 2, có mô hình dẫn truyền synapse |\n",
    "| `RSynaptic` | Synaptic có hồi tiếp |\n",
    "| `Lapicque` | Mô hình RC cổ điển |\n",
    "| `Alpha` | Mô hình màng tế bào theo hàm Alpha |\n",
    "| `LeakyParallel` | Leaky tích hợp xử lý song song (tăng tốc huấn luyện) |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Nơ-ron có hồi tiếp\n",
    "\n",
    "- Các neuron như `RLeaky`, `RSynaptic` sử dụng output spike làm đầu vào cho bước kế tiếp.\n",
    "- Thêm tham số:\n",
    "  - `V`: trọng số hồi tiếp\n",
    "  - `learn_V`: nếu `True`, trọng số hồi tiếp sẽ được học\n",
    "\n",
    "---\n",
    "\n",
    "## ⛓️ Các tham số cấu hình phổ biến\n",
    "\n",
    "| Tham số | Chức năng |\n",
    "|--------|-----------|\n",
    "| `threshold` | Ngưỡng kích hoạt |\n",
    "| `spike_grad` | Hàm gradient xấp xỉ (surrogate) |\n",
    "| `init_hidden` | Nếu `True`, ẩn trạng thái nơ-ron để đơn giản mã |\n",
    "| `inhibition` | Nếu `True`, chỉ nơ-ron có điện thế lớn nhất được phép phát xung |\n",
    "| `learn_beta` | Nếu `True`, hệ số suy giảm được học |\n",
    "| `learn_threshold` | Nếu `True`, ngưỡng kích hoạt được học |\n",
    "| `reset_mechanism` | Cơ chế reset: `\"subtract\"`, `\"zero\"`, `\"none\"` |\n",
    "| `output` | Nếu `True`, trả về cả trạng thái ẩn ngoài spike |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔬 Các nơ-ron nâng cao\n",
    "\n",
    "- `SLSTM`: Spiking LSTM với ngưỡng trạng thái\n",
    "- `SConv2dLSTM`: LSTM tích chập 2D spiking\n",
    "\n",
    "---\n",
    "\n",
    "## 🏗️ Cách xây dựng mạng SNN\n",
    "\n",
    "- Có thể kết hợp `snntorch` với `torch.nn` để xây dựng mô hình SNN.\n",
    "- Hỗ trợ dùng trong `nn.Sequential` hoặc kiến trúc tuỳ chỉnh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd35641",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snntorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnntorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnn\u001b[39;00m\n\u001b[32m      5\u001b[39m alpha = \u001b[32m0.9\u001b[39m\n\u001b[32m      6\u001b[39m beta = \u001b[32m0.85\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'snntorch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "\n",
    "alpha = 0.9\n",
    "beta = 0.85\n",
    "\n",
    "num_steps = 100\n",
    "\n",
    "# Define Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        #initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d100d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
